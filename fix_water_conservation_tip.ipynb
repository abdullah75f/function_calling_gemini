{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk3+/oJ26gcDqLuADiEhuI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullah75f/function_calling_gemini/blob/main/fix_water_conservation_tip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2O2tl_r1YMu"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Installation\n",
        "!pip install requests google-generativeai pyttsx3 gtts beautifulsoup4 -q\n",
        "print(\"Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Imports and Setup (REVISED - Added glm import)\n",
        "import os\n",
        "import requests\n",
        "import random\n",
        "import subprocess # Needed for set_volume\n",
        "import json # Needed for function call responses\n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display # Ensure display is imported\n",
        "import google.generativeai as genai\n",
        "from bs4 import BeautifulSoup\n",
        "import google.ai.generativelanguage as glm # <-- ADD THIS IMPORT\n",
        "\n",
        "# Check the GenAI version (optional but good practice)\n",
        "try:\n",
        "    print(f\"Using google-generativeai version: {genai.__version__}\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not check google-generativeai version: {e}\")\n",
        "# Check glm version if possible\n",
        "try:\n",
        "    # Note: glm might not have a standard __version__ attribute\n",
        "    pass\n",
        "except Exception as e:\n",
        "    pass\n",
        "\n",
        "print(\"Libraries imported.\")"
      ],
      "metadata": {
        "id": "cWzf17Tv1eY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: API Key and Model Initialization\n",
        "_in_colab = False\n",
        "api_key = None\n",
        "model = None # Initialize model variable\n",
        "\n",
        "print(\"Attempting to configure Gemini...\")\n",
        "\n",
        "# Check if running in Colab and import userdata if available\n",
        "try:\n",
        "    from google.colab import userdata\n",
        "    print(\"Successfully imported google.colab.userdata. Running in Colab.\")\n",
        "    _in_colab = True\n",
        "except ImportError:\n",
        "    userdata = None\n",
        "    print(\"Warning: 'google.colab.userdata' not found. Assuming not running in Colab.\")\n",
        "\n",
        "# Get the API Key using the appropriate method\n",
        "try:\n",
        "    if _in_colab and userdata:\n",
        "        print(\"Attempting to retrieve API key from Colab Secrets...\")\n",
        "        # *** Ensure 'GEMINI_API_KEY' matches the name in your Colab Secrets UI ***\n",
        "        api_key = userdata.get('GEMINI_API_KEY')\n",
        "        if not api_key:\n",
        "            raise ValueError(\"Secret 'GEMINI_API_KEY' not found or access not enabled in Colab Secrets.\")\n",
        "        print(\"Successfully retrieved API key from Colab Secrets.\")\n",
        "\n",
        "    else: # Fallback for non-Colab environments\n",
        "        print(\"Attempting to retrieve API key from environment variables (os.getenv)...\")\n",
        "        # *** Looks for an ENVIRONMENT VARIABLE named 'GEMINI_API_KEY' ***\n",
        "        api_key = os.getenv('GEMINI_API_KEY')\n",
        "        if not api_key:\n",
        "            env_var_source = \"environment variables\" if not _in_colab else \"Colab Secrets (import failed) or environment variables\"\n",
        "            raise ValueError(f\"GEMINI_API_KEY not found in {env_var_source}.\")\n",
        "        else:\n",
        "            print(\"Successfully retrieved API key from environment variables.\")\n",
        "\n",
        "    # Configure GenAI and Initialize Model (only if key was found)\n",
        "    if api_key:\n",
        "        print(\"Configuring Gemini with the retrieved API key...\")\n",
        "        genai.configure(api_key=api_key)\n",
        "\n",
        "        # --- Using 1.5 flash model ---\n",
        "        model_name = 'gemini-1.5-flash-latest'\n",
        "        print(f\"Initializing Gemini model '{model_name}'...\")\n",
        "        model = genai.GenerativeModel(model_name)\n",
        "        print(f\"Gemini configured and model '{model.model_name}' initialized successfully.\")\n",
        "    else:\n",
        "        print(\"ERROR: API Key was not retrieved. Cannot configure Gemini or initialize model.\")\n",
        "        model = None # Ensure model is None if configuration failed\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: An error occurred during API key retrieval or Gemini configuration: {e}\")\n",
        "    model = None # Ensure model is None if any error occurs\n",
        "\n",
        "# Final check\n",
        "if model:\n",
        "    print(\"Setup complete. The 'model' variable is ready.\")\n",
        "else:\n",
        "    print(\"Setup failed. The 'model' variable is None. Check errors above.\")"
      ],
      "metadata": {
        "id": "a0MEUeF91gyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Global Variables and Function Definitions (Corrected Scraper)\n",
        "\n",
        "print(\"Defining global variables and functions...\")\n",
        "\n",
        "# --- Global Variables ---\n",
        "DEFAULT_WATER_TIPS_URL = \"https://thewaterproject.org/water_conservation_tips\"\n",
        "WATER_TIPS = [] # Global list to store scraped tips\n",
        "TIP_FILENAME = \"water_conservation_tip.txt\"\n",
        "AUDIO_FILENAME = \"tip_generated_audio.mp3\"\n",
        "LAST_SCRAPED_URL = \"\"\n",
        "\n",
        "\n",
        "# --- Function Definitions (Modified for Function Calling & Corrected Scraper) ---\n",
        "\n",
        "def scrape_water_tips(url):\n",
        "    \"\"\"Scrapes water conservation tips from the given URL using a more specific selector.\"\"\"\n",
        "    global WATER_TIPS, LAST_SCRAPED_URL\n",
        "    print(f\"[Scraping] Attempting to scrape tips from: {url}\")\n",
        "    scraped_list = []\n",
        "    try:\n",
        "        response = requests.get(url, timeout=15)\n",
        "        response.raise_for_status() # Check for HTTP errors\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # --- CORRECTED SELECTOR ---\n",
        "        # Strategy: Find a specific container known to hold the tips, then find the list items within it.\n",
        "        # Based on inspection of thewaterproject.org (this might need updating if the site changes):\n",
        "        # Look for a div that likely contains the main content list.\n",
        "        # Example candidates: a div with specific classes like 'sqs-block-html', or an 'article' tag.\n",
        "        # Let's try finding a common block type first.\n",
        "        # Note: Selectors for other URLs (like the Princeton one) might be different!\n",
        "        # This selector prioritizes the default URL structure.\n",
        "\n",
        "        potential_containers = soup.find_all('div', class_='sqs-block-html') # Find all potential blocks\n",
        "        tip_elements = []\n",
        "\n",
        "        if not potential_containers:\n",
        "             print(f\"[Scraping] Warning: Could not find expected 'div.sqs-block-html' containers on {url}. Falling back to finding all 'li'. This might be inaccurate.\")\n",
        "             # Fallback (less reliable): Find all list items on the page\n",
        "             tip_elements = soup.find_all('li')\n",
        "        else:\n",
        "            print(f\"[Scraping] Found {len(potential_containers)} potential 'div.sqs-block-html' containers. Searching for lists within them.\")\n",
        "            found_list_items = False\n",
        "            for container in potential_containers:\n",
        "                # Look for an unordered list <ul> directly within the container\n",
        "                list_tag = container.find('ul')\n",
        "                if list_tag:\n",
        "                    items = list_tag.find_all('li', recursive=False) # Find direct children 'li'\n",
        "                    if items:\n",
        "                         print(f\"[Scraping] Found {len(items)} list items in a 'ul' within a container.\")\n",
        "                         tip_elements.extend(items)\n",
        "                         found_list_items = True\n",
        "                         # Optional: break here if you are sure the first list found is the correct one\n",
        "                         # break\n",
        "\n",
        "                # If no <ul> found, maybe tips are in <p> tags or direct <li> under the div? (Less likely)\n",
        "                # You might need more sophisticated logic depending on the exact structure.\n",
        "\n",
        "            if not found_list_items:\n",
        "                 print(f\"[Scraping] Warning: Found containers, but no 'ul > li' structure within them. Falling back to finding *all* 'li' on page (less accurate).\")\n",
        "                 tip_elements = soup.find_all('li') # Fallback if specific structure not found inside containers\n",
        "\n",
        "        # --- End CORRECTED SELECTOR ---\n",
        "\n",
        "\n",
        "        if not tip_elements:\n",
        "             print(f\"[Scraping] Warning: No list items ('li') found using any method on {url}.\")\n",
        "             return False # Indicate failure if no elements found\n",
        "\n",
        "        # Extract text, ensuring it's not just whitespace or very short strings (like list numbers)\n",
        "        scraped_list = [tip.get_text(strip=True) for tip in tip_elements if len(tip.get_text(strip=True)) > 5] # Filter short/empty strings\n",
        "\n",
        "        if not scraped_list:\n",
        "            print(f\"[Scraping] Warning: Found list elements but they contained no usable text after filtering.\")\n",
        "            return False # Indicate failure\n",
        "\n",
        "        WATER_TIPS = scraped_list # Assign to global variable ONLY if successful\n",
        "        LAST_SCRAPED_URL = url\n",
        "        print(f\"[Scraping] Successfully scraped and filtered {len(WATER_TIPS)} potential tips from {url}.\")\n",
        "        # print(f\"[Scraping] Sample: {WATER_TIPS[:3]}\") # Optional: Print sample for verification\n",
        "        return True # Indicate success\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"[Scraping] Error fetching URL {url}: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"[Scraping] Error during scraping/parsing for {url}: {e}\")\n",
        "        # print(traceback.format_exc()) # Uncomment for detailed parsing errors\n",
        "        return False\n",
        "\n",
        "# --- Rest of the functions remain the same as in your previous correct Cell 4 ---\n",
        "\n",
        "def get_water_conservation_tip(url: str = None): # Allow None, handle default inside\n",
        "    \"\"\"\n",
        "    Retrieves a random water conservation tip. Scrapes if needed.\n",
        "    Designed for Gemini Function Calling. Returns a dictionary.\n",
        "    \"\"\"\n",
        "    global WATER_TIPS, LAST_SCRAPED_URL, DEFAULT_WATER_TIPS_URL\n",
        "    print(f\"[Function Call] Attempting get_water_conservation_tip(url='{url}')\")\n",
        "    effective_url = url if url else DEFAULT_WATER_TIPS_URL\n",
        "    print(f\"[Function Call] Effective URL: {effective_url}\")\n",
        "\n",
        "    needs_scrape = False\n",
        "    if not WATER_TIPS or effective_url != LAST_SCRAPED_URL:\n",
        "        print(f\"[Function Call] Tips empty or URL differs. Triggering scrape for '{effective_url}'.\")\n",
        "        needs_scrape = True\n",
        "\n",
        "    if needs_scrape:\n",
        "        # ---> ADD LOGGING HERE <---\n",
        "        print(f\"[Function Call] ---> Making HTTP GET request to external endpoint: {effective_url}\")\n",
        "        success = scrape_water_tips(effective_url)\n",
        "        if not success:\n",
        "             print(\"[Function Call Result] Scraping failed.\")\n",
        "             return {\"tip\": f\"Sorry, could not retrieve tips from the source: {effective_url}.\", \"error\": True}\n",
        "\n",
        "    if WATER_TIPS:\n",
        "        selected_tip = random.choice(WATER_TIPS)\n",
        "        # Basic check to filter out obviously non-tip items (like short menu items)\n",
        "        if len(selected_tip.split()) < 4: # If tip is less than 4 words, try again once\n",
        "             print(f\"[Function Call Result] Tip '{selected_tip}' seems too short. Trying again.\")\n",
        "             if len(WATER_TIPS) > 1: # Avoid infinite loop if only one short item exists\n",
        "                 remaining_tips = [t for t in WATER_TIPS if t != selected_tip]\n",
        "                 if remaining_tips:\n",
        "                     selected_tip = random.choice(remaining_tips)\n",
        "        print(f\"[Function Call Result] Returning random tip: '{selected_tip}'\")\n",
        "        return {\"tip\": selected_tip, \"error\": False}\n",
        "    else:\n",
        "        print(\"[Function Call Result] No tips available even after check/scrape.\")\n",
        "        return {\"tip\": \"Sorry, no water conservation tips are currently available.\", \"error\": True}\n",
        "\n",
        "def save_tip(tip: str):\n",
        "    \"\"\"\n",
        "    Saves the provided water conservation tip to a text file.\n",
        "    Designed for Gemini Function Calling. Returns a dictionary.\n",
        "    \"\"\"\n",
        "    global TIP_FILENAME\n",
        "    print(f\"[Function Call] Attempting save_tip(tip='{tip[:50]}...')\")\n",
        "    if not tip or not isinstance(tip, str) or len(tip.strip()) == 0:\n",
        "        print(\"[Function Call Result] Invalid or empty tip provided.\")\n",
        "        return {\"status\": \"Failed: No valid tip provided to save.\", \"filename\": TIP_FILENAME, \"error\": True}\n",
        "    try:\n",
        "        with open(TIP_FILENAME, \"w\", encoding='utf-8') as file: file.write(tip)\n",
        "        msg = f\"Tip successfully saved to {TIP_FILENAME}\"\n",
        "        print(f\"[Function Call Result] {msg}\")\n",
        "        return {\"status\": msg, \"filename\": TIP_FILENAME, \"error\": False}\n",
        "    except Exception as e:\n",
        "        msg = f\"Error saving tip to file '{TIP_FILENAME}': {e}\"\n",
        "        print(f\"[Function Call Result] {msg}\")\n",
        "        return {\"status\": msg, \"filename\": TIP_FILENAME, \"error\": True}\n",
        "\n",
        "def set_volume(level: int):\n",
        "    \"\"\"\n",
        "    Sets the system volume using pactl (Linux specific).\n",
        "    Designed for Gemini Function Calling. Returns a dictionary.\n",
        "    \"\"\"\n",
        "    print(f\"[Function Call] Attempting set_volume(level={level})\")\n",
        "    if not isinstance(level, int) or not 0 <= level <= 150:\n",
        "         msg = \"Error: Volume level must be an integer between 0 and 150.\"\n",
        "         print(f\"[Function Call Result] {msg}\")\n",
        "         return {\"status\": msg, \"error\": True}\n",
        "    if os.name != 'posix':\n",
        "        msg = \"Warning: Volume control via 'pactl' might not work on this OS (non-Linux).\"\n",
        "        print(f\"[Function Call Result] {msg}\")\n",
        "        return {\"status\": msg, \"error\": False}\n",
        "    try:\n",
        "        command = [\"pactl\", \"set-sink-volume\", \"@DEFAULT_SINK@\", f\"{level}%\"]\n",
        "        print(f\"Executing command: {' '.join(command)}\")\n",
        "        result = subprocess.run(command, capture_output=True, text=True, check=False, timeout=5)\n",
        "        if result.returncode == 0:\n",
        "            msg = f\"Attempted to set volume to {level}% via pactl.\"\n",
        "            print(f\"[Function Call Result] {msg}\")\n",
        "            return {\"status\": msg, \"level_set\": level, \"error\": False}\n",
        "        else:\n",
        "            error_message = result.stderr.strip() or result.stdout.strip() or \"Unknown pactl error\"\n",
        "            msg = f\"Error setting volume via pactl (Code {result.returncode}): {error_message}\"\n",
        "            print(f\"[Function Call Result] {msg}\")\n",
        "            return {\"status\": msg, \"error\": True}\n",
        "    except Exception as e:\n",
        "        msg = f\"An unexpected error occurred setting volume: {e}\"\n",
        "        print(f\"[Function Call Result] {msg}\")\n",
        "        return {\"status\": msg, \"error\": True}\n",
        "\n",
        "def tell_tip():\n",
        "    \"\"\"\n",
        "    Reads the water conservation tip from the file aloud using gTTS.\n",
        "    Designed for Gemini Function Calling. Returns a dictionary.\n",
        "    \"\"\"\n",
        "    global TIP_FILENAME, AUDIO_FILENAME\n",
        "    print(\"[Function Call] Attempting tell_tip()\")\n",
        "    try:\n",
        "        if not os.path.exists(TIP_FILENAME):\n",
        "            msg = f\"Error: Tip file '{TIP_FILENAME}' not found. Cannot read tip.\"\n",
        "            print(f\"[Function Call Result] {msg}\")\n",
        "            return {\"status\": msg, \"error\": True}\n",
        "        with open(TIP_FILENAME, \"r\", encoding='utf-8') as file: tip = file.read().strip()\n",
        "        if not tip:\n",
        "             msg = f\"Error: Tip file '{TIP_FILENAME}' is empty.\"\n",
        "             print(f\"[Function Call Result] {msg}\")\n",
        "             return {\"status\": msg, \"error\": True}\n",
        "        if os.path.exists(AUDIO_FILENAME):\n",
        "            try: os.remove(AUDIO_FILENAME)\n",
        "            except OSError as e: print(f\"Warning: Could not remove existing audio file {AUDIO_FILENAME}: {e}\")\n",
        "        print(f\"Generating audio for tip: '{tip[:60]}...'\")\n",
        "        tts = gTTS(text=f\"Here is the saved water conservation tip: {tip}\", lang='en', slow=False)\n",
        "        tts.save(AUDIO_FILENAME)\n",
        "        print(f\"Audio saved to {AUDIO_FILENAME}. Attempting to play...\")\n",
        "        display(Audio(AUDIO_FILENAME, autoplay=True))\n",
        "        msg = f\"Audio for the tip in '{TIP_FILENAME}' generated and playback started.\"\n",
        "        print(f\"[Function Call Result] {msg}\")\n",
        "        return {\"status\": msg, \"audio_file\": AUDIO_FILENAME, \"error\": False}\n",
        "    except Exception as e:\n",
        "        msg = f\"Error during text-to-speech or file reading process: {e}\"\n",
        "        print(f\"[Function Call Result] {msg}\")\n",
        "        return {\"status\": msg, \"error\": True}\n",
        "\n",
        "print(\"Global variables and functions defined (scraper improved).\")"
      ],
      "metadata": {
        "id": "bCedjM6Y1j2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Define Tools for Gemini (REVISED - tell_tip parameters omitted)\n",
        "print(\"\\n--- Defining Tools for Gemini ---\")\n",
        "\n",
        "available_functions = {\n",
        "    \"get_water_conservation_tip\": get_water_conservation_tip,\n",
        "    \"save_tip\": save_tip,\n",
        "    \"set_volume\": set_volume,\n",
        "    \"tell_tip\": tell_tip,\n",
        "}\n",
        "\n",
        "function_declarations = [\n",
        "    glm.FunctionDeclaration(\n",
        "        name=\"get_water_conservation_tip\",\n",
        "        description=\"Retrieves a random water conservation tip, optionally from a specific URL.\",\n",
        "        parameters=glm.Schema( type=glm.Type.OBJECT, properties={\n",
        "                'url': glm.Schema( type=glm.Type.STRING, description=f\"Optional URL. Defaults to {DEFAULT_WATER_TIPS_URL}.\") }\n",
        "        )\n",
        "    ),\n",
        "    glm.FunctionDeclaration(\n",
        "        name=\"save_tip\",\n",
        "        description=f\"Saves a given text string (tip) to the file '{TIP_FILENAME}'.\",\n",
        "        parameters=glm.Schema( type=glm.Type.OBJECT, properties={\n",
        "                'tip': glm.Schema( type=glm.Type.STRING, description=\"The tip text to save.\") },\n",
        "            required=['tip']\n",
        "        )\n",
        "    ),\n",
        "     glm.FunctionDeclaration(\n",
        "        name=\"set_volume\",\n",
        "        description=\"Sets system audio volume (Linux/pactl only).\",\n",
        "        parameters=glm.Schema( type=glm.Type.OBJECT, properties={\n",
        "                'level': glm.Schema( type=glm.Type.INTEGER, description=\"Volume percentage (0-100).\") },\n",
        "            required=['level']\n",
        "        )\n",
        "    ),\n",
        "     # --- FIX for tell_tip ---\n",
        "     glm.FunctionDeclaration(\n",
        "        name=\"tell_tip\",\n",
        "        description=f\"Reads the tip from '{TIP_FILENAME}' aloud using TTS.\"\n",
        "        # No 'parameters' field needed if the function takes no arguments from the model\n",
        "    ),\n",
        "]\n",
        "\n",
        "tools_list = function_declarations\n",
        "print(\"Function declarations created (tell_tip parameters omitted).\")"
      ],
      "metadata": {
        "id": "awG2My1F1ozT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Function Calling Interaction Loop (MODIFIED send_message calls)\n",
        "import google.ai.generativelanguage as glm # Optional: for type hints\n",
        "\n",
        "print(\"\\n--- Starting Function Calling Interaction ---\")\n",
        "\n",
        "# Check if the model is available before proceeding\n",
        "if not model:\n",
        "    print(\"ERROR: Gemini model ('model' variable) is not initialized. Cannot run Function Calling example. Check Cell 3.\")\n",
        "else:\n",
        "    # Start a chat session\n",
        "    chat = model.start_chat(history=[]) # You can manage history here if needed\n",
        "\n",
        "    # --- Define the user's request ---\n",
        "    # Try different prompts to test the function calling logic:\n",
        "    # user_prompt = \"Get me a water saving tip and tell it to me.\"\n",
        "    # user_prompt = \"Find a tip about saving water in the garden, save it, then tell me what you saved.\"\n",
        "    user_prompt = \"Please set volume to 70%, then get a water conservation tip from 'https://environment.princeton.edu/news/10-simple-ways-conserve-water', save the tip you find, and finally read the saved tip aloud.\"\n",
        "    # user_prompt = \"Fetch a random water conservation tip for me, save it to the standard file, and then announce the tip using text-to-speech.\"\n",
        "\n",
        "    print(f\"\\nUser Prompt: '{user_prompt}'\")\n",
        "\n",
        "    # Send the initial prompt with tools enabled\n",
        "    try:\n",
        "        print(\"\\n>> Sending initial prompt to Gemini with tools...\")\n",
        "        # *** Use tools_list instead of tools ***\n",
        "        response = chat.send_message(user_prompt, tools=tools_list)\n",
        "\n",
        "        # --- Loop to handle function calls ---\n",
        "        while True:\n",
        "            # Check if the response contains a function call request\n",
        "            try:\n",
        "                function_call = response.candidates[0].content.parts[0].function_call\n",
        "                if not function_call: # Exit loop if no function call is present\n",
        "                    break\n",
        "            except (AttributeError, IndexError): # Handle cases where response structure is unexpected\n",
        "                 print(\"<< No function call found in the response or response structure invalid.\")\n",
        "                 break\n",
        "\n",
        "            # ** Step 1: Process the FunctionCall request **\n",
        "            # Use glm type for better structure if available, otherwise fallback\n",
        "            try:\n",
        "                api_request = glm.FunctionCall(name=function_call.name, args=dict(function_call.args))\n",
        "            except NameError: # Fallback if glm not imported or fails\n",
        "                api_request = type('obj', (object,), {'name':function_call.name, 'args': dict(function_call.args)})()\n",
        "\n",
        "            print(f\"\\n<< Gemini requested function call: {api_request.name}({api_request.args})\")\n",
        "\n",
        "            # ** Step 2: Look up and execute your Python function **\n",
        "            function_name = api_request.name\n",
        "            if function_name in available_functions:\n",
        "                func_to_call = available_functions[function_name]\n",
        "                args = api_request.args\n",
        "\n",
        "                # Call the function safely\n",
        "                try:\n",
        "                    print(f\"   Executing function: {function_name}...\")\n",
        "                    function_response_data = func_to_call(**args) # Unpack args\n",
        "                    print(f\"   Function returned: {function_response_data}\")\n",
        "\n",
        "                    # ** Step 3: Send the function's result back to the model **\n",
        "                    print(f\">> Sending function response back to Gemini...\")\n",
        "                    # Construct response part (handle potential type errors)\n",
        "                    try:\n",
        "                         function_response_part = glm.Part(function_response=glm.FunctionResponse(name=function_name, response=function_response_data))\n",
        "                    except NameError: # Fallback if glm not imported or fails\n",
        "                         function_response_part = genai.Part.from_function_response(name=function_name, response=function_response_data)\n",
        "\n",
        "                    # *** Use tools_list instead of tools ***\n",
        "                    response = chat.send_message(part=function_response_part, tools=tools_list)\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"   ERROR executing function {function_name}: {e}\")\n",
        "                    print(f\">> Sending error response back to Gemini...\")\n",
        "                    try:\n",
        "                        error_part = glm.Part(function_response=glm.FunctionResponse(name=function_name, response={ \"error\": True, \"status\": f\"Python Error executing {function_name}: {str(e)}\" }))\n",
        "                    except NameError:\n",
        "                        error_part = genai.Part.from_function_response(name=function_name, response={ \"error\": True, \"status\": f\"Python Error executing {function_name}: {str(e)}\" })\n",
        "\n",
        "                    # *** Use tools_list instead of tools ***\n",
        "                    response = chat.send_message(part=error_part, tools=tools_list)\n",
        "                    print(\"   Exiting loop due to function execution error.\")\n",
        "                    break # Exit loop on error\n",
        "\n",
        "            else:\n",
        "                print(f\"   ERROR: Gemini requested unknown function: {function_name}\")\n",
        "                print(\"   Exiting loop due to unknown function request.\")\n",
        "                break # Exit loop\n",
        "\n",
        "        # ** Step 4: Model returns the final text response **\n",
        "        print(\"\\n<< Gemini Final Response:\")\n",
        "        try:\n",
        "           # Check if there's text content before trying to print\n",
        "           if response.candidates and response.candidates[0].content and response.candidates[0].content.parts:\n",
        "               final_text = \"\".join(part.text for part in response.candidates[0].content.parts if hasattr(part, 'text'))\n",
        "               if final_text:\n",
        "                   print(final_text)\n",
        "               else:\n",
        "                   print(\"[No text content in the final response parts]\")\n",
        "           else:\n",
        "                print(\"[Final response structure invalid or empty]\")\n",
        "        except Exception as e:\n",
        "             print(f\"Warning: Could not extract text from final response. Error: {e}\")\n",
        "             # print(\"Full final candidate:\", response.candidates[0]) # Uncomment for debugging\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        print(f\"\\nERROR: An unexpected error occurred during the chat interaction: {e}\")\n",
        "        print(traceback.format_exc()) # Print full traceback for debugging\n",
        "\n",
        "\n",
        "# --- End of Interaction ---\n",
        "print(\"\\n--- Script Finished ---\")"
      ],
      "metadata": {
        "id": "EiAH7a5c1ygX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Original Usage Examples (Manual Function Calls - Adapted)\n",
        "\n",
        "print(\"\\n--- Starting Original Usage Examples (Manual Calls) ---\")\n",
        "\n",
        "# Check if the model is available for Example 1's text generation part\n",
        "if not model:\n",
        "    print(\"WARNING: Gemini model ('model') not initialized. Skipping Example 1 (LLM Tip Generation).\")\n",
        "else:\n",
        "    # --- Example 1: Generate a unique tip using the LLM (Text Generation Only) ---\n",
        "    print(\"\\n--- Example 1: Generating a unique tip via LLM Text Gen ---\")\n",
        "    prompt_llm = \"generate a highly practical water conservation tip for bathroom use\"\n",
        "    try:\n",
        "        print(f\"Sending simple text generation prompt to Gemini: '{prompt_llm}'\")\n",
        "        # NOTE: This call does NOT use function calling tools\n",
        "        response_text_gen = model.generate_content(prompt_llm)\n",
        "\n",
        "        # Safely access generated text\n",
        "        generated_tip_text = None\n",
        "        if response_text_gen.candidates and response_text_gen.candidates[0].content and response_text_gen.candidates[0].content.parts:\n",
        "             generated_tip_text = \"\".join(part.text for part in response_text_gen.candidates[0].content.parts if hasattr(part, 'text'))\n",
        "\n",
        "        if generated_tip_text:\n",
        "            print(\"\\n--- LLM Generated Tip (Text Only) ---\")\n",
        "            print(generated_tip_text)\n",
        "            print(\"---------------------------------------\\n\")\n",
        "\n",
        "            # --- Example 1b: Manually save and speak the generated tip ---\n",
        "            print(\"--- Manually saving and speaking the LLM tip ---\")\n",
        "            save_result = save_tip(generated_tip_text) # Call modified save_tip\n",
        "            print(f\"Save status: {save_result['status']}\")\n",
        "\n",
        "            if not save_result['error']: # Check error flag from save_tip's return dict\n",
        "                speak_result = tell_tip() # Call modified tell_tip\n",
        "                print(f\"Speak status: {speak_result['status']}\")\n",
        "            else:\n",
        "                 print(\"Skipping speaking because saving failed.\")\n",
        "        else:\n",
        "            print(\"Could not generate a tip with the LLM via simple text generation.\")\n",
        "            try:\n",
        "                 print(f\"LLM Response Feedback: {response_text_gen.prompt_feedback}\")\n",
        "            except Exception: pass # Ignore if feedback isn't available\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR during Example 1 (LLM Text Gen): {e}\")\n",
        "\n",
        "# --- End of Examples ---\n",
        "print(\"\\n--- Original Usage Examples Finished ---\")"
      ],
      "metadata": {
        "id": "I3F4p8GE2FoC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}